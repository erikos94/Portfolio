# Portfolio Afasie project
 Naam student: Erik van der Caaij <br>
 Studentnummer: 15059421 <br>
 

 
In dit project is er gekeken naar de mogelijkheden om mensen met Afasie te kunnen helpen met het herstellen van een hersenbloeding. Afasie is als mensen een hersenbloeding hebben gehad in het taalcentrum waardoor mensen niet goed meer kunnen praten of bepaalde fonetische fouten maken. Voor het herstellen van deze variant van de hersenbloeding gaan mensen in sessies met een begeleider oefenen. In veel gevallen zorgt deze één op één sessie voor veel stress hierdoor gaat de spraak bij de patiënten nog lastiger. Onze taak in dit project is dan ook om te kijken hoe wij eventueel door het gebruikt te maken van een computer/robot deze patiënten te kunnen laten oefenen zonder dat zij deze stress mee maken. Wij proberen in dit project hoe een speech2text kan helpen bij het oefenen van mensen met Afasie en proberen deze dan te ontwikkelen. <br>

In dit project wordt er gebruikt gemaakt van Scrum hierdoor weten we precies wat iedereen in het projectgroepje aan het doen is en kunnen we ook mensen erop aanspreken als bepaalde taken niet zijn uitgevoerd. Elke sprint duurt twee weken en we hebben zo'n twintig weken voor dit project.<br>

Hieronder staan een aantal screenshots van de online courses die zijn afgerond. Door deze cursussen heb ik kennis verkregen over python en machine learning. 

<H2> Datacamp screenshot </H2> <br>
Hier heb ik de eerste tien weken aanbesteed met als resultaat dat ik python heb geleerd(<a href='https://www.scrumwise.com/scrum/#/backlog-item/3248-datacamp-python-intro-course/id-84641-10738-147'> Scrumwise ticket</a> ). Daarna heb ik dit gebruikt in het project om zo bestanden kunnen cleanen en te visualiseren. De volgende hoofdstukken zijn hierbij aan bod gekomen: Intro to Python for Data Science, Intermediate Python for Data Science, Customizing plots, Introduction and flat files, Writing your own functions, Python Data Science Toolbox(Part2), Data ingestion & inspection en Exploratory data. <br>


 
![datacamp assignments](https://user-images.githubusercontent.com/42931518/50977664-07ae9080-14f3-11e9-9238-3efd6134bab5.png)<br>
Afbeelding1: Hier staan de cursussen die ik heb afgerond voor datacamp.<br>

<h2> Coursera screenshot </H2><br>
Coursera heb ik ook in de eerste tien weken van de deze minor afgerond om zo genoeg kennis te hebben voor de toets en te zorgen dat ik kennis genoeg heb en dit kan toepassen op het project van Afasie(<a href='https://www.scrumwise.com/scrum/#/backlog-item/4405-coursera-maken/id-84641-13599-0'>Scrumwise ticket </a>). In Coursera heb ik week1, week2, week3 en week 6 gemaakt. Hieronder staat de screenshot met bijbehorende percentages die ik gehaald heb voor de quizzen aan het einde van elk hoofdstuk.<br>

![coursera](https://user-images.githubusercontent.com/42931518/49797999-760c0180-fd41-11e8-905d-271a428a70b2.png) <br>
Afbeelding2: Hier staan de cursussen die ik heb afgerond voor coursera.<br>


 <h2> Domain knowledge(Literature, jargon, evaluation, existing data sets)</h2> <br>
 
Tijdens het doen van Research naar wat Afasie is heb ik gebruikt gemaakt van een aantal bronnen. Deze bronnen heb ik gebruikt om te zien wat überhaupt Afasie is en om in te lezen in het domein.<br>

 
 Hieronder Staan een aantal documenten die te maken hebben met research doen naar het domein.<br>
 
 In dit document is er research gedaan naar wat Afasie precies is en of het bijvoorbeeld over kan gaan. Daarnaast heb ik gekeken of er bepaalde woorden zijn waar Afasie vaker bij optreed.  (<a href='https://www.scrumwise.com/scrum/#/backlog-item/3224-deskresearch-afasie/id-84641-10738-18'> Scrumwise ticket </a>).
[Deskresearch.Afasie_Erik (1).pdf](https://github.com/erikos94/Portfolio/files/2744856/Deskresearch.Afasie_Erik.1.pdf)
 <br>
 
 
Ik heb in het onderstaande document onderzoek gedaan naar wat fonologie, syntaxis, semantiek, antoniemen, synoniemen en hyponiemen zijn. Dit heb ik met de rest van de groep gedeeld, omdat deze begrippen veel worden gebruikt in dit domein.In(<a href='https://www.scrumwise.com/scrum/#/backlog-item/3323-in-hoeverre-kan-er-via-bestaande-stt-drie-types-fouten-worden-opgelostsemantic/id-84641-10884-56'>Scrumwise ticket </a>). Dit heeft bijgedragen aan het project, omdat ik hierdoor weet om welke fouten het gaat en hoe je deze termen uit elkaar kan halen en zien wat dit betekend.
[Research deelvragen Erik(concept) (1).pdf](https://github.com/erikos94/Portfolio/files/2744870/Research.deelvragen.Erik.concept.1.pdf) <br>
 
Hieronder staat het document waarin ik research heb gedaan naar classifiers. Hierbij heb ik gekeken naar hoe ik bepaalde classifiers kan gebruiken en hoe accuraat deze zijn. Hiervoor heb ik wetenschappelijk artikelen gebruikt. Daarnaast heb ik de link gelegd om te zien of we deze classifiers uit de literatuur konden gebruiken voor ons project. We hebben uit de literatuur de hoogst scorende classifiers gehaald en deze hebben wij toegepast op ons project.(<a href='https://www.scrumwise.com/scrum/#/backlog-item/3692-research-classificatie-algoritmes-voor-clasificere-van-diphone-clasifier/id-84641-11576-9'>Scrumwise ticket </a>). <br>
 [Research voor classifier en phoneme boundary.pdf](https://github.com/erikos94/Portfolio/files/2744877/Research.voor.classifier.en.phoneme.boundary.pdf)
 
<h2>Predictive Models</h2><br>
Hieronder staan een aantal predictive models die ik heb geprobeerd om te zien of deze werkten voor ons project.
<ul>
 <li>SVM(<a href='https://www.scrumwise.com/scrum/#/backlog-item/3851-classifier-trainen-met-10-zinnen-van-foxvorge-data/id-84641-12037-7'>Scrumwise ticket </a>):[SVM.pdf](https://github.com/erikos94/Portfolio/files/2744881/SVM.pdf)</li><br>
Om SVM te kunnen begrijpen heb ik een aantal tutorials opgezocht en heb ik hiermee geoefend. Ook heb ik hiermee een beetje gespeeld om te zien wat het precies doet. [SVM oefening.pdf](https://github.com/erikos94/Portfolio/files/2745817/SVM.oefening.pdf)
De datum in het document is de datum van exporteren naar PDF.<br>
 
 
 Ik heb SVM(Support Vector Machine) gebruikt om een classifier te maken voor de Phoneme Boundary classifier van Koray. Na het testen van deze SVM zagen we dat accuracy, precision en recall niet goed waren(helaas, is hier geen screenshot, omdat de dataset is gewijzigd). Dit hebben we toen overlegd en uiteindelijk was Koray zijn classifier beter en zijn we niet verder gegaan met de SVM. 
 <br><br>
 
 
 
  
 <li>(LSTM) Keras</li><br>
 
 Ik heb het LSTM model in Keras gebruikt om een Sequence2Sequence model te maken. De LSTM is gebruikt om zinnen van Nederlands naar het Nederlands te vertalen. Dit was een experiment om te zien of dit uiteindelijk ook kon met MFCC Features -> klanken. Dit was namelijk ons uiteindelijke doel.(<a href='https://www.scrumwise.com/scrum/#/backlog-item/4406-lstm-en-fra-bekijken-en-toepassen-op-nl-nl-zinnen/id-84641-13599-10'> Scrumwise ticket </a>).<br> [dataset MFCC -_keras.pdf](https://github.com/erikos94/Portfolio/files/2729455/dataset.MFCC.-_keras.pdf)<br><br>
 
 Hierna heb ik geprobeerd om van MFCC features naar woorden te gaan. Het model gaf aan dat het 80% accuraat was, maar omdat dat code was veranderd kreeg ik een foutmelding bij het gebruiken van de output. Toen ik dit had opgelost bleek dat de 80% een verkeerd beeld had gegeven. De worden die eruit kwamen, kwamen helemaal niet overeen met de woorden die erin gingen.
 
Toen heb ik samen met Jeroen de code aangepast, zodat er meer data ingeladen kon worden en hebben we dropouts toegevoegd en hebben we daarna ook nog een attention model geprobeerd, maar dit gaf ook niet het gewenste resultaat en de resultaten bleven slecht.<br> 
 
 [dataset MFCC -_Keras-Woorden (2).pdf](https://github.com/erikos94/Portfolio/files/2729459/dataset.MFCC.-_Keras-Woorden.2.pdf)

</ul>

 
 <h2>Data preparation</h2><br>
 Voor het ophalen van data en het maken van een dictionary heb ik het volgende script geschreven. Deze dictionary was nodig voor PocketSphinx. Deze dictonary is gebruikt om een lijst van woorden te genereren en deze aan pocketsphinx te geven zodat hij deze woorden gaat herkennen. Daarnaast waren er nog meerdere modellen nodig om een werkend Speech regonition systeem te bouwen(acoustic model, phonetic dictionary en language model). <br><br>
 
 [lijst maken van woorden voor dictonary.pdf](https://github.com/erikos94/Portfolio/files/2744891/lijst.maken.van.woorden.voor.dictonary.pdf)<br>
 
 Daarnaast kon Pocketsphinx niet overweg met een aantal speciale characters dus deze heb ik weggehaald uit het bestand door de volgende code: Hierdoor herkende Pocketsphinx deze tekens wel.
 <br>
 
[code voor cleanen woordfile.pdf](https://github.com/erikos94/Portfolio/files/2744899/code.voor.cleanen.woordfile.pdf)

Daarnaast heb ik ook een stukje geschreven om een [woord] [klank] achter elkaar te krijgen. Dit stond namelijk achter elkaar en elke [woord] [klank] moest op een nieuwe regel beginnen, dus heb ik dit stukje code geschreven. Dit konden we dan gebruiken voor ons model van PocketSphinx. 
[[Woord] [klank] cleanen..pdf](https://github.com/erikos94/Portfolio/files/2745847/Woord.klank.cleanen.pdf)
 

 
 <h2> Data Visualization </h2><br>
 
We hebben verschillende papers bekeken hoe we van een audiosignaal naar features kunnen komen. Daarvoor hebben we meerdere "pipelines" kunnen vinden in wetenschappelijke artikelen. Om te zien wat precies de FFT en MFCC doet hebben Koray en ik een aantal woorden ingesproken in deze weergegeven in een plot. We wisten al wat het deed, alleen nog niet hoe de visualisatie eruit zag en of we aan de hand hiervan nieuwe inzichten kregen. (<a href='https://www.scrumwise.com/scrum/#/backlog-item/3772-voorbeeld-creeren-visualisatie-van-fft-en-mfcc/id-84641-11988-34'>Scrumwise ticket </a>) <br>

Dit heeft ons geholpen om een beeld te vormen over FFT. Hieronder staan een aantal voorbeelden hoe dit eruit ziet.
 
![erik woorden plot fft](https://user-images.githubusercontent.com/42931518/49877233-41717600-fe25-11e8-88ac-daa86d9511de.png)<br>
 Afbeelding3: Een plot van vijf uitgesproken woorden door Erik in FFT.<br>

![koray woorden plot fft](https://user-images.githubusercontent.com/42931518/49877238-42a2a300-fe25-11e8-8e69-a33dc26265dd.png)<br>
Afbeelding4: Een plot van vijf uitgesproken woorden door Koray in FFT.<br>

We weten alleen niet precies wat dit resultaat inhoud, maar omdat beide plots er anders uitzien denken we dat het iets te maken heeft met de frequenctie toon. Daarna hebben we deze woorden ook nog is een keer in een WAV file geplot om te zien of hier iets opvallends is, maar dit viel ook alles mee. Je kan goed zien dat de ene sneller de woorden heeft uitgesproken dan de ander.

Dit is voor vijf ingesproken woorden door Erik.
![wav files woorden_erik](https://user-images.githubusercontent.com/42931518/49878716-8cd95380-fe28-11e8-98ff-bb6f2c37c38f.png) <br>
Afbeelding5: Een plot van vijf uitgesproken woorden door Erik in Wav.<br>

Dit is voor vijf ingesproken woorden door Koray. 
![koray woorden wav](https://user-images.githubusercontent.com/42931518/49878714-8a76f980-fe28-11e8-8c58-c74d47b60d93.png)<br>
Afbeelding6: Een plot van vijf uitgesproken woorden door Koray in Wav.<br>

De bovenstaande WAV files kunnen doormiddel van een library dus makkelijk gevisualiseerd worden, alleen zie ik niet echt aan de voorkant van wat er gebeurd. 

 <h2> Data collection </h2><br>
 
 We zijn met de data collection vrij lang bezig geweest, omdat we eerst dachten dat we de data van onze opdrachtgever vroeg zouden krijgen en hiermee aan de slag konden gaan. Dit bleek achteraf niet het geval, want de data die we kregen waren alleen WAV files van mensen met Afasie. Voor een Speech Recognition systeem heb je WAV files nodig, maar ook getransribeerde tekst die erbij hoord en timestamps van de woorden die worden gezegd. Daarom hebben we veel kleine testjes gedaan met opgenomen audio waarin wij bepaalde woorden of getallen in hebben gesproken.  
 

Ook heb ik research gedaan naar een database met audio die we zouden kunnen gebruiken en hierbij kwam ik uit op de site van de UVA(universiteit van Amsterdam). http://www.fon.hum.uva.nl/IFA-SpokenLanguageCorpora/IFAcorpus/ (<a href='https://www.scrumwise.com/scrum/#/backlog-item/4408-research-naar-datasets/id-84641-13655-1'>Scrumwise Ticket </a>)

Deze dataset is 1.8GB groot hebben we doormiddel van een scraper die Koray had gemaakt van de site afgehaald zodat we in ieder geval data hadden waarmee we aan de slag konden. 

Daarnaast hebben we in week 14 een dataset gevonden. Deze dataset werd in veel experimenten genoemd, maar er werd ook bij genoemd dat deze dataset €100,- kostte. Deze hadden we ook eerder in het project gevonden, maar omdat we net begonnen waren hebben we deze niet meteen geopperd. Na het overwegen om deze dataset te komen, kwamen we erachter dat deze dataset gratis te downloaden was. 

Het corpus gesproken Nederlands omvat ongeveer 10miljoen Nederlandse woorden waarvan er 250.000 woorden ook geannoteerd en gecontroleerd zijn. Hierbij wordt bedoeld dat een klein deel van de corpus audio heeft met bijbehorende uitgeschreven zinnen, woorden en timestamps en zelfs phonemen.(<a href='https://www.scrumwise.com/scrum/#/backlog-item/3852-research-cgn-dataset-achterhalen/id-84641-12037-13'>Scrumwise ticket </a>)
 
<h2> Diagnostics of the learning process :learning rate, loss function, overfitting and under fitting </h2><br>
 Ik had een voorbeeld gevonden van een Seq2seq (sequence to sequence) waarin een zin in het Engels werd vertaald naar het frans(<a href='https://www.scrumwise.com/scrum/#/backlog-item/4407-seq2seq-bekijken-en-zien-hoe-we-dit-kunnen-toepassen-op-afasie/id-84641-13599-17'>Scrumwise ticket </a>). Hier ben ik een beetje mee gaan spelen om te zien of dit ook gebruikt kan worden voor ons project(
[Test LSTM woorden en zinnen.pdf](https://github.com/erikos94/Portfolio/files/2745975/Test.LSTM.woorden.en.zinnen.pdf)
). De resultaten waren verbazingwekkend goed. Zie hieronder: <br> In de plaatsjes is de test lijn eigenlijk de validatie. Dus in de volgende plaatjes is het train en validatie.

![acc_zinnen_nl](https://user-images.githubusercontent.com/42931518/50691690-c5d4a480-1031-11e9-8320-2bd3dff64bfc.png)<br>
Afbeelding7: Een plot van de accuracy van train en de test(validatie)dataset voor een LSTM model van Nederlandse zin naar een Nederlandse zin(X=epochs, y=accuracy).<br>

![loss_zinnen_nl](https://user-images.githubusercontent.com/42931518/50691687-c5d4a480-1031-11e9-989f-5056d3947158.png)<br>
Afbeelding8:Een plot van de loss van train en de test(validatie)dataset voor een LSTM model van Nederlandse zin naar een Nederlandse zin(X=epochs, y=accuracy)<br>

![output_zinnen_nl](https://user-images.githubusercontent.com/42931518/50691688-c5d4a480-1031-11e9-8205-c2cc8939fa56.png)<br>
Afbeelding9: Een plot van de output van een LSTM model van Nederlandse zin naar een Nederlandse zin over de test(validatie) dataset.<br>

Doordat dit model goed werkte heb ik toen als input de MFCC features genomen en als output de Nederlandse woorden. De accuracy gaf aan dat dit 80% was alleen de output gaf een foutmelding. Hierdoor kon ik niet zien of dit wel klopte. Na dit opgelost te hebben met Jeroen zagen we dat de output helemaal niet overeen kwam met input. Hierdoor zijn we aan het kijken hoe we dit beter kunnen krijgen. 
  
 <h2> Communication (presentations, summaries, paper) </h2><br>
 
 <b> paper: </b> <br>
 
 Ik heb zoals met de rest van de groep aan alle presentaties meegewerkt om deze te maken. Daarnaast heb ik vier presentations gehouden. De presenaties die ik heb gehouden staan hieronder genoemd.

<li>Week 5: [Kopie van Aphasia week5.pdf](https://github.com/erikos94/Portfolio/files/2744916/Kopie.van.Aphasia.week5.pdf) <br></li>
<li> Week 7:[_Aphasia week7.pdf](https://github.com/erikos94/Portfolio/files/2744917/_Aphasia.week7.pdf)<br></li>
<li> week 9: [Kopie van Aphasia week 9.pdf](https://github.com/erikos94/Portfolio/files/2744918/Kopie.van.Aphasia.week.9.pdf)<br></li>
<li> week 14:[Aphasia week 14.pdf](https://github.com/erikos94/Portfolio/files/2744919/Aphasia.week.14.pdf)<br></li>

<h2>List the tickets from the Scrum backlog that you worked on, linked to deliverables, own experiments, etc.
Add any other assignment you feel is evidence of your abilities </h2><br>

Omdat wij tijdens dit project de hele tijd met zijn vieren waren hebben we er voor gezorgd dat iedereen zijn sterke punten kon benutten hierdoor heb ik meer documentatie werk gedaan dan andere. Hieronder een lijst wat ik denk dat wel toegevoegde waarde is geweest aan dit project. <br>


<ul>
 <li> Ik heb een plan van aanpak gemaakt, omdat dit altijd nodig is in een begin van een project. Dit is omdat men dan weet wat het probleem is en welk stuk je afbakend. Daarnaast wil je opdezelfde lijn zitten als de opdrachtgever met het project en hierdoor weet je of je de opdracht goed hebt begrepen. Het plan van aanpak staat hier:  
[Plan van aanpak_AfasieDEF.pdf](https://github.com/erikos94/Portfolio/files/2744938/Plan.van.aanpak_AfasieDEF.pdf) (<a href='https://www.scrumwise.com/scrum/#/backlog-item/3266-pva-maken/id-84641-10790-7'> Scrumwise ticket </a>)</li>
 
 <li>
 Ik heb een interviewprotocool opgesteld, omdat ik het belangrijk vond dat we van tervoren al research hadden gedaan over het project zodat we in het interview gerichtere vragen konden stellen. Daarnaast laat het je dan ook denken over een aantal aspecten waar je van tervoren niet over hebt nagedacht. Bijvoorbeeld in welke omgeving ga je deze persoon interviewen, kan het zijn dat als je met z'n vijfen gaat dat ze zich bedreigd voelt. Uiteindelijk zorgt deze aanpak voor gerichtere vragen en ziet ook de opdrachtgever dat je in dit onderwerp geintresseerd bent. Hieronder staat het interview protocool zoals wij het eerste gesprek met de opdrachtgever hebben gehouden. [Interviewprotocol - AfasieExpert.pdf](https://github.com/erikos94/Portfolio/files/2744943/Interviewprotocol.-.AfasieExpert.pdf) (<a href='https://www.scrumwise.com/scrum/#/task/5022-interview-protocol-opstellen/id-84641-10738-102'> Scrumwise ticket</a>) </li>
 
 <li>
 Ik heb onderzoek gedaan naar Arfabet en SAMPA/XSAMPA. Dit heb ik gedaan omdat we dan zelf een paar wooren kunnen omzetten naar een alfabet, om hiermee te gaan trainen. Daarnaast gebruikt PocketSphinx ARFABET en moesten we weten hoe dit Arfabet in elkaar zat. Hiermee heb ik bereikt dat we wisten hoe PocketSphinx bepaalde klanken omzet naar tekens.
 [Klanken samenvatting CMUSPHINX(PORTFOLIO).docx](https://github.com/erikos94/Portfolio/files/2729482/Klanken.samenvatting.CMUSPHINX.PORTFOLIO.docx) (<a href='https://www.scrumwise.com/scrum/#/backlog-item/3523-find-out-more-about-phonemes-the-origin-and-how-they-work/id-84641-11280-0'> Scrumwise ticket </a>)

<li> Selecteren van audio voor Afasie. Dit heb ik gedaan omdat heel veel audio hebben gekregen van de opdrachtgever, hierin zaten alle audio bestanden, dus ook met mensen die bijna geen woord kunnen zeggen. Wij focussen ons nu op de de fonologie afwijkingen dus deze moesten we eruit filteren. Dit heeft als resultaat dat we deze audio konden gebruiken voor onze Speech Recognition[Schema welke goed.pdf](https://github.com/erikos94/Portfolio/files/2744945/Schema.welke.goed.pdf) <a href='https://www.scrumwise.com/scrum/#/backlog-item/3712-selecteren-audio-van-aphasia/id-84641-11715-23'>Scrumwise ticket </a></li>
<li>
 In het begin van het project heb ik een test gedaan met de api van Google Speech2Text om te zien wat deze maakt van een aantal ingesproken worden. Grotendeels pakte google API wel de juiste woorden op, maar als iemand begon te stotteren of onduidelijk sprak dan maakt google er ook niet veel waardevols van. [Api google code.docx](https://github.com/erikos94/Portfolio/files/2736965/Api.google.code.docx)<a href='https://www.scrumwise.com/scrum/#/backlog-item/3329-oefenen-met-de-gemaakte-s2tgoogle/id-84641-10884-94'>Scrumwise ticket </a></li>
<ul>

